<!DOCTYPE html>
<html lang="de">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Multimodale Diffusion für selbstüberwachtes Vortraining | Michael Mommert</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Deep-Learning-Modelle, die auf Diffusionsprozessen basieren, zeigen ein großes Potenzial in einer Vielzahl von generativen Aufgaben, wie z.B. der Bildgenerierung. Für Anwendungen in der Fernerkundung sind generative Modelle jedoch nicht so verbreitet. Die Frage, die wir zu beantworten versucht haben, ist, ob Diffusionsprozesse verwendet werden können, um Modelle für diskriminative Aufgaben effizient vorzutrainieren?">
    <meta name="generator" content="Hugo 0.135.0">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



  
    <link rel="stylesheet" href="/css/override.css">
  

    

    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/de/research/2024-07-12-multimodal_diffusion_for_self_supervised_pretraining/">
    

    <meta property="og:url" content="http://localhost:1313/de/research/2024-07-12-multimodal_diffusion_for_self_supervised_pretraining/">
  <meta property="og:site_name" content="Michael Mommert">
  <meta property="og:title" content="Multimodale Diffusion für selbstüberwachtes Vortraining">
  <meta property="og:description" content="Deep-Learning-Modelle, die auf Diffusionsprozessen basieren, zeigen ein großes Potenzial in einer Vielzahl von generativen Aufgaben, wie z.B. der Bildgenerierung. Für Anwendungen in der Fernerkundung sind generative Modelle jedoch nicht so verbreitet. Die Frage, die wir zu beantworten versucht haben, ist, ob Diffusionsprozesse verwendet werden können, um Modelle für diskriminative Aufgaben effizient vorzutrainieren?">
  <meta property="og:locale" content="de">
  <meta property="og:type" content="article">
    <meta property="article:section" content="research">
    <meta property="article:published_time" content="2024-07-12T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-07-12T00:00:00+00:00">
    <meta property="article:tag" content="Erdbeobachtung">
    <meta property="article:tag" content="Deep Learning">
    <meta property="article:tag" content="Diffusion">
    <meta property="article:tag" content="Multimodal">
    <meta property="article:tag" content="Selbstüberwachtes Lernen">

  <meta itemprop="name" content="Multimodale Diffusion für selbstüberwachtes Vortraining">
  <meta itemprop="description" content="Deep-Learning-Modelle, die auf Diffusionsprozessen basieren, zeigen ein großes Potenzial in einer Vielzahl von generativen Aufgaben, wie z.B. der Bildgenerierung. Für Anwendungen in der Fernerkundung sind generative Modelle jedoch nicht so verbreitet. Die Frage, die wir zu beantworten versucht haben, ist, ob Diffusionsprozesse verwendet werden können, um Modelle für diskriminative Aufgaben effizient vorzutrainieren?">
  <meta itemprop="datePublished" content="2024-07-12T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-07-12T00:00:00+00:00">
  <meta itemprop="wordCount" content="321">
  <meta itemprop="keywords" content="Erdbeobachtung,Deep Learning,Diffusion,Multimodal,Selbstüberwachtes Lernen">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Multimodale Diffusion für selbstüberwachtes Vortraining">
  <meta name="twitter:description" content="Deep-Learning-Modelle, die auf Diffusionsprozessen basieren, zeigen ein großes Potenzial in einer Vielzahl von generativen Aufgaben, wie z.B. der Bildgenerierung. Für Anwendungen in der Fernerkundung sind generative Modelle jedoch nicht so verbreitet. Die Frage, die wir zu beantworten versucht haben, ist, ob Diffusionsprozesse verwendet werden können, um Modelle für diskriminative Aufgaben effizient vorzutrainieren?">

	
  </head>

  <body class="ma0 avenir bg-nearwhite">

    
   
  

  
  <header class="cover bg-top" style="background-image: url('http://localhost:1313/remote_sensing.png');">
    <div class="bg-black-40">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/de/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Michael Mommert
      
    </a>
    <div class="flex-l items-center">
      
<h4></h4>
<ul class="pl0 mr3">
    
    <li class="list f5 f4-ns fw4 dib pr3">
        <a class="hover-white no-underline white-90" href="/research/2024-07-12-multimodal_diffusion_for_self_supervised_pretraining/">en</a>
    </li>
    
</ul>


      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/de/research/" title="Forschung Seite">
              Forschung
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/de/bio/" title="Lebenslauf Seite">
              Lebenslauf
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/de/publications/" title="Publikationen Seite">
              Publikationen
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <div class="f2 f1-l fw2 white-90 mb0 lh-title">Multimodale Diffusion für selbstüberwachtes Vortraining</div>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      
      
      
      <div>Deep-Learning-Modelle, die auf Diffusionsprozessen basieren, zeigen ein großes Potenzial in einer Vielzahl von generativen Aufgaben, wie z.B. der Bildgenerierung. Für Anwendungen in der Fernerkundung sind generative Modelle jedoch nicht so verbreitet. Die Frage, die wir zu beantworten versucht haben, ist, ob Diffusionsprozesse verwendet werden können, um Modelle für diskriminative Aufgaben effizient vorzutrainieren?</div>
      
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2024-07-12T00:00:00Z">Juli 12, 2024</time>
      

      
      
        <span class="f6 mv4 dib tracked"> - 2 Minuten </span>
        <span class="f6 mv4 dib tracked"> - 321 Wörter </span>
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>Diffusionsprozesse sind am besten dafür bekannt, Modelle zu trainieren, die Bilder aus Text generieren. Die Idee hinter Diffusionsprozessen ist recht einfach: Man nimmt ein Bild und zerstört die Informationen schrittweise, indem man Gaußsches Rauschen anwendet. Ein Diffusionsmodell lernt nun, die ursprünglichen Informationen zwischen zwei Schritten wiederherzustellen (d.h. das Rauschen zu entfernen). Vollständig trainiert sind diese Modelle dazu in der Lage, fotorealistische Bilder aus Rauschen zu erzeugen.</p>
<p>Um ein Bild aus Text zu erstellen, muss der Diffusionsprozess mit einem Textprompt konditioniert werden. Dies ist eine Möglichkeit, zusätzliche Informationen bereitzustellen, um den generativen Prozess zu steuern.</p>
<p>Während generative Modelle in der Erdbeobachtung nicht so verbreitet sind, fragten wir uns, ob wir einen Diffusionsprozess nutzen könnten, um unsere Modelle auf selbstüberwachter Basis vorzutrainieren.</p>
<p>Dazu haben wir ein Diffusionsmodell auf unserem <a href="http://localhost:1313/de/research/2023-07-21-ben-ge_extending_bigearthnet_with_geographical_and_environmental_data/">ben-ge Datensatz</a> trainiert. Wir geben Sentinel-1- und Sentinel-2-Rasterdaten als verschiedene Bänder in das Modell ein und experimentieren mit anderen Datenmodalitäten als Eingabe für den Konditionierungsmechanismus.</p>
<p>Hat es funktioniert?</p>
<div class="wrapper"
     style="display: block; margin-left: auto; margin-right: auto; 
            margin-bottom: 20px; width: 90%;">
  <figure class="image"
	  style="display: block; margin-left: auto; margin-right: auto; 
                 width: ;">
    <a href="diffusion_qualitative_sample.png">
        <img src="diffusion_qualitative_sample.png" alt=""  align="center">
    </a>
    <figcaption style="font-style: italic; text-align: justify;">
      Synthetische Bilder, die mit unserer Methode generiert wurden. Die Spalten zeigen synthetisch erzeugte Datenmodalitäten zu verschiedenen Zeitpunkten (von oben nach unten) des Diffusionsprozesses. Im letzten Zeitpunkt entstehen realistische und konsistente Szenen (über die Datenmodalitäten hinweg) aus dem Rauschen.
    </figcaption>
  </figure>
</div>

<p>Wie die obige Abbildung zeigt, ist das Modell dazu in der Lage, realistisch aussehende Sentinel-2-Szenen zu generieren. Noch wichtiger ist jedoch, dass die Sentinel-1 SAR-Daten, die es für dasselbe Bild  generiert, sehr konsistent mit den Sentinel-2-Daten sind. Dadurch glauben wir, dass das Modell nützliche Informationen lernt. Aber sind die gelernten Repräsentationen nützlich für darauf folgende diskriminative Aufgaben wie die Klassifizierung und Segmentierung von Landnutzung/Landbedeckung?</p>
<p>Die Antwort scheint klar: Das Vortraining mit Diffusion funktioniert gut für die Segmentierungsaufgabe, jedoch nicht so sehr für die Klassifizierungsaufgaben. Darüber hinaus scheint die Konditionierung des Modells die Ergebnisse zu verbessern.</p>
<p>Weitere Details gibt es in unserem Beitrag zu IGARSS 2024 (siehe unten).</p>
<h1 id="bibliographie">Bibliographie</h1>
<ul>
<li>Alexander Lontke, Michael Mommert, Damian Borth, &ldquo;<em>Multi-Modal Diffusion for Self-Supervised Pretraining</em>&rdquo;, <a href="https://ieeexplore.ieee.org/abstract/document/10640509">IEEE International Geoscience and Remote Sensing Symposium 2024</a>, 2024.</li>
</ul>
<ul class="pa0">
  
   <li class="list di">
     <a href="/de/tags/erdbeobachtung/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Erdbeobachtung</a>
   </li>
  
   <li class="list di">
     <a href="/de/tags/deep-learning/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Deep Learning</a>
   </li>
  
   <li class="list di">
     <a href="/de/tags/diffusion/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Diffusion</a>
   </li>
  
   <li class="list di">
     <a href="/de/tags/multimodal/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Multimodal</a>
   </li>
  
   <li class="list di">
     <a href="/de/tags/selbst%C3%BCberwachtes-lernen/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Selbstüberwachtes Lernen</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Ähnliches</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/de/research/2023-07-21-ben-ge_extending_bigearthnet_with_geographical_and_environmental_data/">Ben-Ge - Erweiterung von Bigearthnet mit geografischen und umweltbezogenen Daten</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/de/research/2022-06-07-contrastive_self-supervised_data_fusion_for_satellite_imagery/">Kontrastives selbstüberwachtes Lernen für multimodale Erdbeobachtungsdaten</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/de/research/2022-06-20-traffic_noise_estimation_from_satellite_imagery_with_deep_learning/">Schätzung des Verkehrslärms aus Satellitenbildern mit Deep Learning</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/de/research/2021-12-14-estimating_power_plant_greenhouse_gas_emissions_from_satellite_imagery/">Abschätzung von Treibhausgasemissionen von Kraftwerken aus Satellitenbildern</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/de/research/2021-11-18-estimation_of_surface_level_no2_from_remote_sensing_data/">Bestimmung von NO2-Konzentrationen an der Erdoberfläche aus Fernerkundungsdaten</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/de/research/2021-11-17-commercial_vehicle_traffic_detection_from_satellite_imagery_with_deep_learning/">Erkennung von LKWs auf Satellitenbildern mit Deep Learning</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/de/research/2021-06-16-power_plant_classification_from_remote_imaging_with_deep_learning/">Klassifizierung von Kraftwerken aus Satellitenbildern mit Deep Learning</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/de/research/2020-12-07-characterization_of_industrial_smoke_plumes_from_remote_sensing_data/">Charakterisierung industrieller Abgasfahnen aus Fernerkundungsdaten</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/de/research/2020-04-22-automated-cloud-detection-with-machine-learning/">Automatisierte Wolkenerkennung mit maschinellem Lernen</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black-60 bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/de/" >
    &copy;  Michael Mommert 2024 
  </a>

  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="mailto:michael.mommert@hft-stuttgart.de" >
    michael.mommert@hft-stuttgart.de
  </a>

  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://www.hft-stuttgart.com" >
    Stuttgart University of Applied Sciences, Schellingstr. 24, 70174 Stuttgart, Germany
  </a>

  </div>
</footer>

  </body>
</html>
